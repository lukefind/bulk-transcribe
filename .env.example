# =========================
# Bulk Transcribe â€“ Server Configuration
# =========================

# Web server
PORT=8476

# Compute backend is auto-detected at runtime via /api/runtime
# The system will only offer backends that are actually available:
#   - Docker on macOS: cpu only (Metal not available in containers)
#   - Linux + NVIDIA: cpu, cuda
#   - macOS native (DMG): cpu, metal (if torch.mps available)
# This legacy DEVICE variable is ignored; backend is selected per-job.
DEVICE=cpu

# =========================
# Worker configuration
# =========================

# Default workers for CPU mode
DEFAULT_WORKERS=2

# Hard cap for UI dropdown (safety)
MAX_WORKERS=8

# =========================
# GPU (NVIDIA CUDA) config
# =========================

# If DEVICE=cuda, this controls which GPUs are visible.
# Examples:
#   CUDA_VISIBLE_DEVICES=0      (use first GPU only)
#   CUDA_VISIBLE_DEVICES=0,1    (use GPU 0 and 1)
#   CUDA_VISIBLE_DEVICES=       (empty = all GPUs)
CUDA_VISIBLE_DEVICES=

# Optional: cap GPU memory usage (advanced users only)
# Example: 0.9 = max 90% of VRAM
CUDA_MEMORY_FRACTION=

# =========================
# Application mode
# =========================

# server = multi-user mode with session isolation (no folder paths from clients)
# local = single-user mode (allows folder picker, legacy endpoints)
APP_MODE=server

# =========================
# Storage paths (inside container)
# =========================

# Root data directory (sessions stored under DATA_ROOT/sessions/)
DATA_ROOT=/data

# Legacy paths (only used in local mode)
INPUT_DIR=/data/input
OUTPUT_DIR=/data/output

# =========================
# Session & Job limits
# =========================

# Session expiry (hours since last activity)
SESSION_TTL_HOURS=24

# Job data retention (days)
JOB_TTL_DAYS=7

# Maximum upload size per request (MB)
MAX_UPLOAD_MB=500

# Maximum files per transcription job
MAX_FILES_PER_JOB=50

# Maximum total storage per session (MB)
MAX_TOTAL_SESSION_MB=2000

# Job stale detection (minutes without update before marking failed)
JOB_STALE_MINUTES=30

# Maximum job runtime (minutes before auto-cancel)
MAX_JOB_RUNTIME_MINUTES=120

# Force secure cookies (set to 1 if behind HTTPS proxy)
COOKIE_SECURE=0

# =========================
# Admin
# =========================

# Admin token for /api/admin/stats endpoint (leave empty to disable)
ADMIN_TOKEN=

# =========================
# HuggingFace (pyannote diarization)
# =========================

# Only required if you enable diarization features
HF_TOKEN=

# =========================
# Diarization limits (CPU safety)
# =========================

# Maximum audio duration (seconds) for CPU diarization
# Longer files will be rejected with DIARIZATION_TOO_LONG_CPU
# Default: 180 (3 minutes) - safe for 8GB RAM
# Increase to 300-600 if you have 16GB+ RAM
MAX_DIARIZATION_DURATION_SECONDS=180

# Maximum diarization runtime before timeout (minutes)
# Prevents infinite hangs if model stalls
MAX_DIARIZATION_MINUTES=30

# Maximum size for converted WAV temp files (MB)
# Prevents disk exhaustion from huge conversions
DIARIZATION_MAX_WAV_MB=500

# =========================
# Diarization Policy (auto-split chunking)
# =========================

# Server hard cap for max diarization duration (seconds)
# Users cannot exceed this via UI
DIARIZATION_SERVER_MAX_DURATION_SECONDS=1800

# Default max duration shown in UI (seconds)
# Should be <= server max
DIARIZATION_DEFAULT_MAX_DURATION_SECONDS=180

# Chunk size bounds for auto-split (seconds)
DIARIZATION_POLICY_MIN_CHUNK_SECONDS=60
DIARIZATION_POLICY_MAX_CHUNK_SECONDS=600

# Overlap = chunk_seconds * ratio, clamped to min/max
DIARIZATION_POLICY_DEFAULT_OVERLAP_RATIO=0.03
DIARIZATION_POLICY_MIN_OVERLAP_SECONDS=2
DIARIZATION_POLICY_MAX_OVERLAP_SECONDS=15

# =========================
# Remote GPU Worker
# =========================

# URL of the remote GPU worker service (EG Runpod)
# Example: https://gpu-worker.example.com or http://worker:8477
REMOTE_WORKER_URL=

# Shared secret token for worker authentication
# Generate with: openssl rand -hex 32
REMOTE_WORKER_TOKEN=

# Remote worker mode:
#   off      = all jobs run locally (default)
#   optional = UI shows "Run on GPU" toggle, user chooses per-job
#   required = all jobs automatically run on remote worker
REMOTE_WORKER_MODE=off

# Job timeout for remote execution (seconds)
REMOTE_WORKER_TIMEOUT_SECONDS=7200

# Poll interval for checking worker status (seconds)
REMOTE_WORKER_POLL_SECONDS=2

# Upload mode: pull (worker downloads from controller) or push (controller uploads to worker)
# pull is recommended - simpler and avoids duplicate uploads
REMOTE_WORKER_UPLOAD_MODE=pull

# Controller base URL (required for signed download URLs in pull mode)
# Example: https://your-server.example.com
CONTROLLER_BASE_URL=

# Secret key for signing download URLs (generate a random string)
SECRET_KEY=

# =========================
# Logging
# =========================

# debug | info | warning | error
LOG_LEVEL=info

# Suppress noisy third-party warnings (pyannote, torchaudio, speechbrain)
# Set to 0 to see all warnings for debugging
SUPPRESS_THIRD_PARTY_WARNINGS=1

